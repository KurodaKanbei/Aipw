{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# import general modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.svm import OneClassSVM\n",
    "import xgboost as xgb\n",
    "from helpers import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import specialised modules\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features are calculated for the whole data. This only shows how it was done, the results are already saved as csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_features = False\n",
    "\n",
    "if new_features:\n",
    "    # prepare the X data for analysis\n",
    "    X_ = pd.read_csv('X_train.csv', engine='c')\n",
    "    X_.drop(columns='id', inplace=True)\n",
    "    col_names = X_.index\n",
    "    # transform the data\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    X_processed = pd.DataFrame(scaler.fit_transform(X_.transpose()).transpose())\n",
    "    # convert the frame to np arrays and remove the nans\n",
    "    X_processed = [item[~np.isnan(item)] for item in X_processed.to_numpy()]\n",
    "    #extracting noise features\n",
    "    noise_df = extract_noise_features(X_processed)\n",
    "    X_pp = preprocess(X_processed)\n",
    "    #extract features based on temporal and frequental things\n",
    "    df = extract_features(X_pp)\n",
    "    df = pd.concat([df, noise_df], axis=1)\n",
    "    df.to_csv('train_features.csv')\n",
    "    X_ = pd.read_csv('X_test.csv', engine='c')\n",
    "    X_.drop(columns='id', inplace=True)\n",
    "    col_names = X_.index\n",
    "    # transform the data\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    X_processed = pd.DataFrame(scaler.fit_transform(X_.transpose()).transpose())\n",
    "    # convert the frame to np arrays and remove the nans\n",
    "    X_processed = [item[~np.isnan(item)] for item in X_processed.to_numpy()]\n",
    "    #extracting noise features\n",
    "    noise_df = extract_noise_features(X_processed)\n",
    "    X_pp = preprocess(X_processed)\n",
    "    #extract features based on temporal and frequental things\n",
    "    df = extract_features(X_pp)\n",
    "    df = pd.concat([df, noise_df], axis=1)\n",
    "    df.to_csv('test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>delta</th>\n",
       "      <th>delta_hr</th>\n",
       "      <th>var_hr</th>\n",
       "      <th>mean_rp</th>\n",
       "      <th>min_rp</th>\n",
       "      <th>max_rp</th>\n",
       "      <th>...</th>\n",
       "      <th>fbin4</th>\n",
       "      <th>fbin5</th>\n",
       "      <th>fbin6</th>\n",
       "      <th>fbin7</th>\n",
       "      <th>fbin8</th>\n",
       "      <th>fbin9</th>\n",
       "      <th>fbin10</th>\n",
       "      <th>fmean</th>\n",
       "      <th>fstd</th>\n",
       "      <th>snr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5117.000000</td>\n",
       "      <td>5117.000000</td>\n",
       "      <td>5117.000000</td>\n",
       "      <td>5117.000000</td>\n",
       "      <td>5117.000000</td>\n",
       "      <td>5112.000000</td>\n",
       "      <td>5112.000000</td>\n",
       "      <td>5117.000000</td>\n",
       "      <td>5117.000000</td>\n",
       "      <td>5117.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5117.000000</td>\n",
       "      <td>5117.000000</td>\n",
       "      <td>5117.000000</td>\n",
       "      <td>5117.000000</td>\n",
       "      <td>5117.000000</td>\n",
       "      <td>5117.000000</td>\n",
       "      <td>5117.000000</td>\n",
       "      <td>5117.000000</td>\n",
       "      <td>5117.000000</td>\n",
       "      <td>5117.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.002463</td>\n",
       "      <td>0.070645</td>\n",
       "      <td>-0.457473</td>\n",
       "      <td>0.361939</td>\n",
       "      <td>0.819412</td>\n",
       "      <td>24.323780</td>\n",
       "      <td>78.459586</td>\n",
       "      <td>251.014966</td>\n",
       "      <td>186.859683</td>\n",
       "      <td>319.230995</td>\n",
       "      <td>...</td>\n",
       "      <td>5.690467</td>\n",
       "      <td>8.057255</td>\n",
       "      <td>43.461169</td>\n",
       "      <td>264.264152</td>\n",
       "      <td>742.820371</td>\n",
       "      <td>2034.227951</td>\n",
       "      <td>4367.077673</td>\n",
       "      <td>15.493249</td>\n",
       "      <td>11.017222</td>\n",
       "      <td>1.171283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.020138</td>\n",
       "      <td>0.026860</td>\n",
       "      <td>0.181384</td>\n",
       "      <td>0.132330</td>\n",
       "      <td>0.253523</td>\n",
       "      <td>24.526138</td>\n",
       "      <td>165.437718</td>\n",
       "      <td>53.370393</td>\n",
       "      <td>73.384114</td>\n",
       "      <td>110.647062</td>\n",
       "      <td>...</td>\n",
       "      <td>7.806650</td>\n",
       "      <td>7.998656</td>\n",
       "      <td>30.528956</td>\n",
       "      <td>187.327562</td>\n",
       "      <td>516.488174</td>\n",
       "      <td>1399.889770</td>\n",
       "      <td>3064.881309</td>\n",
       "      <td>6.534356</td>\n",
       "      <td>5.221419</td>\n",
       "      <td>9.092662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.088494</td>\n",
       "      <td>0.007019</td>\n",
       "      <td>-0.863601</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.133684</td>\n",
       "      <td>0.128576</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>84.484211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180340</td>\n",
       "      <td>0.292570</td>\n",
       "      <td>3.644086</td>\n",
       "      <td>10.171169</td>\n",
       "      <td>27.114916</td>\n",
       "      <td>96.757229</td>\n",
       "      <td>187.310408</td>\n",
       "      <td>1.443830</td>\n",
       "      <td>0.919977</td>\n",
       "      <td>-86.639990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.013215</td>\n",
       "      <td>0.049633</td>\n",
       "      <td>-0.610884</td>\n",
       "      <td>0.272008</td>\n",
       "      <td>0.636020</td>\n",
       "      <td>6.819845</td>\n",
       "      <td>2.950418</td>\n",
       "      <td>217.868421</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.955814</td>\n",
       "      <td>3.711286</td>\n",
       "      <td>24.938766</td>\n",
       "      <td>148.433714</td>\n",
       "      <td>420.051147</td>\n",
       "      <td>1125.084032</td>\n",
       "      <td>2329.188564</td>\n",
       "      <td>10.284164</td>\n",
       "      <td>7.075823</td>\n",
       "      <td>-2.190189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.005024</td>\n",
       "      <td>0.074205</td>\n",
       "      <td>-0.468133</td>\n",
       "      <td>0.352294</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>14.430810</td>\n",
       "      <td>12.749544</td>\n",
       "      <td>249.625000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.094540</td>\n",
       "      <td>5.549801</td>\n",
       "      <td>35.357642</td>\n",
       "      <td>219.707239</td>\n",
       "      <td>641.945791</td>\n",
       "      <td>1818.335679</td>\n",
       "      <td>3956.120848</td>\n",
       "      <td>15.793983</td>\n",
       "      <td>10.903850</td>\n",
       "      <td>3.618137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.006963</td>\n",
       "      <td>0.091962</td>\n",
       "      <td>-0.308277</td>\n",
       "      <td>0.437741</td>\n",
       "      <td>1.034896</td>\n",
       "      <td>34.511353</td>\n",
       "      <td>71.124028</td>\n",
       "      <td>282.285714</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>352.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.675709</td>\n",
       "      <td>9.011174</td>\n",
       "      <td>51.986088</td>\n",
       "      <td>319.650996</td>\n",
       "      <td>885.903092</td>\n",
       "      <td>2427.495005</td>\n",
       "      <td>5274.263190</td>\n",
       "      <td>20.209531</td>\n",
       "      <td>14.298418</td>\n",
       "      <td>6.966429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.100316</td>\n",
       "      <td>0.144354</td>\n",
       "      <td>-0.022360</td>\n",
       "      <td>0.834691</td>\n",
       "      <td>1.373629</td>\n",
       "      <td>139.490994</td>\n",
       "      <td>2191.155354</td>\n",
       "      <td>794.888889</td>\n",
       "      <td>638.000000</td>\n",
       "      <td>2697.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>91.624780</td>\n",
       "      <td>95.006648</td>\n",
       "      <td>352.761849</td>\n",
       "      <td>1923.670048</td>\n",
       "      <td>4348.883447</td>\n",
       "      <td>10595.437550</td>\n",
       "      <td>19144.804254</td>\n",
       "      <td>37.314805</td>\n",
       "      <td>46.819868</td>\n",
       "      <td>21.845221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean          var          min          max        delta  \\\n",
       "count  5117.000000  5117.000000  5117.000000  5117.000000  5117.000000   \n",
       "mean     -0.002463     0.070645    -0.457473     0.361939     0.819412   \n",
       "std       0.020138     0.026860     0.181384     0.132330     0.253523   \n",
       "min      -0.088494     0.007019    -0.863601     0.003723     0.133684   \n",
       "25%      -0.013215     0.049633    -0.610884     0.272008     0.636020   \n",
       "50%      -0.005024     0.074205    -0.468133     0.352294     0.861386   \n",
       "75%       0.006963     0.091962    -0.308277     0.437741     1.034896   \n",
       "max       0.100316     0.144354    -0.022360     0.834691     1.373629   \n",
       "\n",
       "          delta_hr       var_hr      mean_rp       min_rp       max_rp  ...  \\\n",
       "count  5112.000000  5112.000000  5117.000000  5117.000000  5117.000000  ...   \n",
       "mean     24.323780    78.459586   251.014966   186.859683   319.230995  ...   \n",
       "std      24.526138   165.437718    53.370393    73.384114   110.647062  ...   \n",
       "min       0.128576     0.002755    84.484211     1.000000    88.000000  ...   \n",
       "25%       6.819845     2.950418   217.868421   128.000000   258.000000  ...   \n",
       "50%      14.430810    12.749544   249.625000   196.000000   298.000000  ...   \n",
       "75%      34.511353    71.124028   282.285714   240.000000   352.000000  ...   \n",
       "max     139.490994  2191.155354   794.888889   638.000000  2697.000000  ...   \n",
       "\n",
       "             fbin4        fbin5        fbin6        fbin7        fbin8  \\\n",
       "count  5117.000000  5117.000000  5117.000000  5117.000000  5117.000000   \n",
       "mean      5.690467     8.057255    43.461169   264.264152   742.820371   \n",
       "std       7.806650     7.998656    30.528956   187.327562   516.488174   \n",
       "min       0.180340     0.292570     3.644086    10.171169    27.114916   \n",
       "25%       1.955814     3.711286    24.938766   148.433714   420.051147   \n",
       "50%       3.094540     5.549801    35.357642   219.707239   641.945791   \n",
       "75%       5.675709     9.011174    51.986088   319.650996   885.903092   \n",
       "max      91.624780    95.006648   352.761849  1923.670048  4348.883447   \n",
       "\n",
       "              fbin9        fbin10        fmean         fstd          snr  \n",
       "count   5117.000000   5117.000000  5117.000000  5117.000000  5117.000000  \n",
       "mean    2034.227951   4367.077673    15.493249    11.017222     1.171283  \n",
       "std     1399.889770   3064.881309     6.534356     5.221419     9.092662  \n",
       "min       96.757229    187.310408     1.443830     0.919977   -86.639990  \n",
       "25%     1125.084032   2329.188564    10.284164     7.075823    -2.190189  \n",
       "50%     1818.335679   3956.120848    15.793983    10.903850     3.618137  \n",
       "75%     2427.495005   5274.263190    20.209531    14.298418     6.966429  \n",
       "max    10595.437550  19144.804254    37.314805    46.819868    21.845221  \n",
       "\n",
       "[8 rows x 91 columns]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print general description\n",
    "df = pd.read_csv('train_features.csv').drop(['Unnamed: 0'],axis=1)\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace inf with nan\n",
    "df.replace([np.inf, -np.inf], np.NaN, inplace=True)\n",
    "imp = KNNImputer(n_neighbors=4, weights='distance')\n",
    "# imp_mean = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "df_X = pd.DataFrame(imp.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('y_train.csv')\n",
    "y.drop(columns='id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size reduced from 5117 to 4726\n"
     ]
    }
   ],
   "source": [
    "samples_before = df_X.shape[0]\n",
    "\n",
    "# trans = ExperimentalTransformer(OneClassSVM(nu=0.995))\n",
    "model = IsolationForest(contamination=\"auto\")\n",
    "outl_pred = model.fit_predict(df_X)\n",
    "mask = outl_pred != -1\n",
    "\n",
    "X_selection, y = df_X[mask], y[mask]\n",
    "\n",
    "samples_after = X_selection.shape[0]\n",
    "\n",
    "print(f'Data size reduced from {samples_before} to {samples_after}')\n",
    "df_X = X_selection\n",
    "\n",
    "data_train_backup = df_X.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find most important features with a random forest, since different libraries are used and they showed very inconsistant performance.\n",
    "The 40 best features are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance (optional)\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "rfe = RFE(estimator=RandomForestClassifier(n_estimators=200, n_jobs=-1), n_features_to_select=40, step=0.05)\n",
    "rfe.fit(df_X, y.values.ravel())\n",
    "df_X = rfe.transform(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_selection, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB is often used for tabular data for many reasons and it's potential was again showed in the recent paper [Tabular Data: Deep Learning is Not All You Need](https://arxiv.org/abs/2106.03253).\n",
    "\n",
    "The hyperopt package is used to maximize the AUC while finding the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "space = {'max_depth': hp.quniform(\"max_depth\", 3, 12, 1),\n",
    "         'gamma': hp.uniform('gamma', 1, 9),\n",
    "         'reg_alpha': hp.quniform('reg_alpha', 40, 180, 1),\n",
    "         'reg_lambda': hp.uniform('reg_lambda', 0, 1),\n",
    "         'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "         'min_child_weight': hp.quniform('min_child_weight', 0, 10, 1),\n",
    "         'n_estimators': 1000,\n",
    "         'seed': 0\n",
    "         }\n",
    "\n",
    "def objective(space):\n",
    "    clf = xgb.XGBClassifier(\n",
    "        use_label_encoder=False,n_jobs=-1,\n",
    "        n_estimators=space['n_estimators'], max_depth=int(space['max_depth']), gamma=space['gamma'],\n",
    "        reg_alpha=int(space['reg_alpha']), min_child_weight=int(space['min_child_weight']),\n",
    "        colsample_bytree=int(space['colsample_bytree']))\n",
    "\n",
    "    evaluation = [(X_train, y_train.values.ravel()),\n",
    "                  (X_test, y_test.values.ravel())]\n",
    "\n",
    "    clf.fit(X_train, y_train.values.ravel(),\n",
    "            eval_set=evaluation, eval_metric=\"mlogloss\",\n",
    "            early_stopping_rounds=10, verbose=False)\n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    accuracy = f1_score(y_test.values.ravel(), pred, average='micro')\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 500/500 [05:41<00:00,  1.46trial/s, best loss: -0.7428087986463621]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, objective='multi:softprob',\n",
       "              predictor='auto', random_state=0, reg_alpha=0, ...)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 500,\n",
    "                        trials = trials)\n",
    "\n",
    "best_xgb = xgb.XGBClassifier(best_hyperparams)\n",
    "best_xgb.fit(X_train, y_train.values.ravel(), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88740839 0.62569832 0.70170015 0.48648649]\n",
      "0.8104906937394247\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, best_xgb.predict(X_test), average=None))\n",
    "print(f1_score(y_test, best_xgb.predict(X_test), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using the model on the submission, it was finetuned on the whole data, since we should make use of all data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('test_features.csv').drop(['Unnamed: 0'],axis=1)\n",
    "data_test.replace([np.inf, -np.inf], np.NaN, inplace=True)\n",
    "# print(len(data_test.columns), len(data_train_backup.columns))\n",
    "data_test = pd.DataFrame(imp.fit(data_train_backup).transform(data_test), columns=data_train_backup.columns)\n",
    "data_test = rfe.transform(data_test)\n",
    "\n",
    "y_prob = None\n",
    "n_rounds = 1\n",
    "for r in range(n_rounds):\n",
    "    best_xgb = xgb.XGBClassifier(best_hyperparams)\n",
    "    best_xgb.fit(df_X, y.values.ravel(), verbose=False, eval_metric='mlogloss')\n",
    "    y_test_prob = best_xgb.predict_proba(data_test)\n",
    "    if y_prob is None:\n",
    "        y_prob = np.zeros_like(y_test_prob)\n",
    "    y_prob = y_prob + y_test_prob\n",
    "y_test = np.argmax(y_prob, axis=1)\n",
    "data_out = {\"id\" : np.arange(len(y_test)), \"y\": y_test}\n",
    "df_out = pd.DataFrame(data_out)\n",
    "df_out.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8623811480223281, 'gamma': 1.2017606607223974, 'max_depth': 4.0, 'min_child_weight': 0.0, 'reg_alpha': 40.0, 'reg_lambda': 0.19101490078046782}\n"
     ]
    }
   ],
   "source": [
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d978ae2e8a86257f048fc033d3eda8d42f083b4862912b2e1169677d4916a1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
