{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e56c71f-655a-44b9-be89-f2eaa2682da6",
   "metadata": {},
   "source": [
    "## Load libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60a94525-6c27-424d-86f5-806fe267e0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1212, 832)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "import seaborn as sb\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression, SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from scipy.stats import pearsonr\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "\n",
    "X = pd.read_csv(os.path.join(\"data\", \"X_train.csv\"),\n",
    "                delimiter=',',\n",
    "                index_col = 'id')\n",
    "y = pd.read_csv(os.path.join(\"data\", \"y_train.csv\"),\n",
    "                delimiter=',',\n",
    "                index_col='id')\n",
    "\n",
    "\n",
    "# idx = []\n",
    "# for i, feature in enumerate(X.columns):\n",
    "#     values = X[feature].dropna(0)\n",
    "#     mx = values.max()\n",
    "#     mn = values.min()\n",
    "#     if mn > 0 and abs((mx - mn) / mn - .1) < 0.05:\n",
    "#         idx.append(feature)\n",
    "# X = X.drop(idx, axis=1)\n",
    "# print(X.shape)\n",
    "# nan_idx = np.isnan(X)\n",
    "\n",
    "\n",
    "\n",
    "nan_idx = np.isnan(X)\n",
    "imputer = KNNImputer(n_neighbors=20)\n",
    "X_imp = imputer.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train = X_imp\n",
    "y_train = y.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "# model = sklearn.ensemble.IsolationForest(max_samples=0.5, contamination=0.025)\n",
    "# # model = sklearn.neighbors.LocalOutlierFactor(contamination=0.025)\n",
    "# outl_pred = model.fit_predict(X_imp)\n",
    "# mask = outl_pred != -1\n",
    "# X_cleaned, y_cleaned = X_cleaned[mask, :], y_cleaned[mask]\n",
    "# print(X_cleaned.shape, y_cleaned.shape)\n",
    "# y_train = y_cleaned\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fd904df-f4b5-467e-a54e-b3372b11f824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_net/troubadour/tianfwang/conda_envs/pytorch3d/lib/python3.9/site-packages/scipy/stats/_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "/scratch_net/troubadour/tianfwang/conda_envs/pytorch3d/lib/python3.9/site-packages/scipy/stats/_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "/scratch_net/troubadour/tianfwang/conda_envs/pytorch3d/lib/python3.9/site-packages/scipy/stats/_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "/scratch_net/troubadour/tianfwang/conda_envs/pytorch3d/lib/python3.9/site-packages/scipy/stats/_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['x2', 'x15', 'x21', 'x23', 'x26', 'x27', 'x29', 'x40', 'x69', 'x77',\n",
       "       ...\n",
       "       'x778', 'x780', 'x783', 'x788', 'x796', 'x801', 'x817', 'x819', 'x823',\n",
       "       'x824'],\n",
       "      dtype='object', length=189)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_corr = 0.1\n",
    "\n",
    "df_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "feat = df_train.iloc[:,1:].columns.tolist()\n",
    "corr = {}\n",
    "for f in feat:\n",
    "    x_f = df_train[[f]][f].values\n",
    "    key = f\n",
    "    corr[key] = pearsonr(x_f,y_train)[0]\n",
    "\n",
    "data_corr = pd.DataFrame(corr, index=['lin']).T\n",
    "selected_feat = data_corr.loc[(abs(data_corr['lin']) >= thresh_corr) ].index\n",
    "selected_feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df238af3-9986-447b-a744-a94315907419",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy = X_train.copy()\n",
    "\n",
    "X_train = sklearn.preprocessing.StandardScaler().fit(X_train_copy).transform(X_train)\n",
    "X_train  = pd.DataFrame(X_train, columns=X.columns)\n",
    "\n",
    "X_train = X_train[selected_feat].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a2f7675-ac5a-49c1-bee1-06fb8414f215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'num_leaves': 32,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "selector = RFE(model, step=0.1, n_features_to_select=60, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af0ac021-b867-47ca-815d-494f9b91fffa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 189 features.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Fitting estimator with 171 features.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Fitting estimator with 153 features.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Fitting estimator with 135 features.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Fitting estimator with 117 features.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Fitting estimator with 99 features.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Fitting estimator with 81 features.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Fitting estimator with 63 features.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LGBMRegressor(bagging_fraction=0.8, bagging_freq=5,\n",
       "                            feature_fraction=0.5, learning_rate=0.05,\n",
       "                            num_leaves=32, objective='regression', task='train',\n",
       "                            verbose=0),\n",
       "    n_features_to_select=60, step=0.1, verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.fit(X_train,y_train.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d377544-ecb3-42c1-bfa5-d7a141facc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1212, 189)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a49b8858-cc83-475e-940f-6b7d84bc2910",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned, y_cleaned = X_train, y_train\n",
    "\n",
    "X_train = selector.transform(X_train)\n",
    "\n",
    "\n",
    "model = sklearn.ensemble.IsolationForest(contamination=\"auto\")\n",
    "outl_pred = model.fit_predict(X_train)\n",
    "mask = outl_pred != -1\n",
    "\n",
    "X_train, y_train = X_train[mask, :], y_train[mask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4cba181-4bab-42cf-8a8c-560b85a453e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1147, 120)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6ba68df-390b-4d2a-bbf0-93c6765cfa08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_net/troubadour/tianfwang/conda_envs/pytorch3d/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNNImputer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# X_train_backup = X_train.copy()\n",
    "# X_train = sklearn.preprocessing.StandardScaler().fit(X_train_backup).transform(X_train)\n",
    "\n",
    "X_test = pd.read_csv(os.path.join(\"data\", \"X_test.csv\"),\n",
    "                     delimiter=',',\n",
    "                     index_col='id')\n",
    "X_test_backup = X_test\n",
    "# X_test = X_test.drop(idx, axis=1)\n",
    "X_test = imputer.fit(X_imp).transform(X_test)\n",
    "X_test_stdised = sklearn.preprocessing.StandardScaler().fit(X_train_copy).transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2a0df17-b898-487d-b957-1644b4ff1b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_stdised = pd.DataFrame(X_test_stdised, columns=X_test_backup.columns, index=X_test_backup.index)\n",
    "X_test_stdised = X_test_stdised[selected_feat].values\n",
    "\n",
    "X_test_stdised = selector.transform(X_test_stdised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "177b12bb-6244-492a-99ac-671788ed60e7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train itr 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(trial_itr):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain itr \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     X_train_split, X_val_split, y_train_split, y_val_split \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(X_train, y_train, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.15\u001b[39m) \n\u001b[1;32m     11\u001b[0m     lgb_train \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_train_split, y_train_split)\n\u001b[1;32m     14\u001b[0m     lgb_eval \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_val_split, y_val_split, reference\u001b[38;5;241m=\u001b[39mlgb_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "def r2_sc(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'r2', r2_score(labels, preds), True\n",
    "\n",
    "best = 0\n",
    "trial_itr = 100\n",
    "for i in range(trial_itr):\n",
    "    print(f\"train itr {i}\")\n",
    "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size = 0.15) \n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_train_split, y_train_split)\n",
    "    \n",
    "    \n",
    "    lgb_eval = lgb.Dataset(X_val_split, y_val_split, reference=lgb_train)\n",
    "\n",
    "\n",
    "    params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'num_leaves': 32,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.5,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    model = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=1000,\n",
    "                    feval=r2_sc,\n",
    "                    valid_sets={lgb_train, lgb_eval},\n",
    "                     early_stopping_rounds=100)\n",
    "    y_val_predict = model.predict(X_val_split, num_iteration=model.best_iteration)\n",
    "        \n",
    "    \n",
    "    \n",
    "    res = r2_score(y_val_split, y_val_predict)\n",
    "    \n",
    "    print(res)\n",
    "    if res > best:\n",
    "        print(f\"New Best result {res}\")\n",
    "        best = res\n",
    "        y_pred = model.predict(X_test_stdised, num_iteration=model.best_iteration)\n",
    "        f = open(f\"out{best}.csv\", \"w\")\n",
    "        f.write(\"id,y\\n\")\n",
    "        for i,x in enumerate(y_pred):\n",
    "            f.write(\"{},{}\\n\".format(i,x))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3fed8f-1203-407f-bcac-719026ced2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "print(glob.glob(\"./test/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "634935b9-0973-4836-b57a-308eb5a81f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./esb/out0.7342315896063321.csv', './esb/out0.7346987687926609.csv', './esb/out0.7372855502427849.csv', './esb/out0.7247752664242797.csv']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "inputs = glob.glob(\"./esb/*\")\n",
    "print(inputs)\n",
    "res = [0.0]*776\n",
    "\n",
    "for f in inputs:\n",
    "    f = open(f).readlines()[1:]\n",
    "    for l in f:\n",
    "        sp = l.split(',')\n",
    "        idx, s = int(sp[0]), float(sp[1])\n",
    "        res[idx] += s\n",
    "out = open(\"./ensemble_debug.csv\", \"w\")\n",
    "out.write(\"id,y\\n\")\n",
    "for i in range(776):\n",
    "    out.write(\"{},{}\\n\".format(i, (res[i]/len(inputs))))\n",
    "out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
